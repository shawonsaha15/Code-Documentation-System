{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWoa0gcbqbmmAYnFjet9oH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Documentation System**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fbWuYvUAn2pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**\n",
        "\n",
        "This AI-powered Code Documentation System automates the generation of readable explanations and structured documentation for code snippets. Using 'gemini-2.0-flash' model's API, it provides summaries, identifies functions, suggests missing docstrings, and recommends improvements. Enhanced with embeddings and a RAG-style retrieval system, it delivers context-aware insights and supports both JSON and Markdown outputs. The tool simplifies code understanding, aiding developers and learners in writing and maintaining better software."
      ],
      "metadata": {
        "id": "tOAjRraDucsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "The Code Documentation Assistant is an interactive AI-powered tool designed to help developers generate high-quality explanations, summaries, and improvement suggestions for code snippets. Leveraging large language models with few-shot prompting, structured JSON outputs, and retrieval-augmented generation (RAG), this assistant supports multiple explanation formats—ranging from formal summaries to engaging, story-like descriptions.\n",
        "\n",
        "It integrates advanced features like code embeddings, vector search using FAISS, and long context window support through the Gemini API, allowing it to retrieve similar code examples to enrich understanding. The system also provides basic evaluation of explanation quality, making it an excellent tool for learning, onboarding, and improving code maintainability.\n",
        "\n",
        "Whether you're a junior developer trying to understand unfamiliar code or a senior engineer documenting a large codebase, this assistant streamlines the process with intelligent, context-aware outputs."
      ],
      "metadata": {
        "id": "tmQiJtzrud-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Methodology**\n",
        "\n",
        "<insert image>\n",
        "\n",
        "The figure shows the system architecture of the application. The Code Documentation System employs a hybrid methodology combining traditional natural language processing with modern Retrieval-Augmented Generation (RAG) techniques to enhance the explanation and documentation of code snippets. The workflow begins at the user interface layer, where users input code, select the desired output format (structured JSON or story-style narrative), and choose between a basic explanation or a RAG-enhanced analysis. Once the input is received, the code undergoes parsing to extract key structures and functions, followed by embedding generation using a high-dimensional vector space (768 dimensions), optimized for code similarity tasks and multilingual support.\n",
        "\n",
        "These embeddings, along with the original code snippets, are stored in a FAISS vector database, which enables efficient similarity search. In RAG mode, the system queries this vector database to retrieve contextually similar code snippets, which are then merged to construct an enriched prompt. This context-aware prompt is crafted using few-shot examples and format-specific templates to guide the language model’s generation process effectively. The system ensures output consistency through strict JSON structure enforcement or by crafting an engaging and educational narrative in story mode.\n",
        "\n",
        "The language model processes the prompt and returns a raw response, which is then cleaned and formatted appropriately. In the case of JSON output, the system attempts direct parsing or extraction from markdown code blocks. For story output, narrative coherence and educational tone are prioritized. The final explanation undergoes a quality evaluation phase, assessing completeness, clarity, and adherence to the expected format. Evaluation metrics are calculated, and feedback is generated for both users and system developers.\n",
        "\n",
        "Methodologically, the system emphasizes prompt engineering, embedding strategies, and retrieval quality to ensure accuracy and depth. Error handling mechanisms are built in to manage model anomalies and output inconsistencies. Overall, the design ensures a modular, interpretable, and scalable approach to AI-powered code documentation, enabling developers to better understand, improve, and share their code."
      ],
      "metadata": {
        "id": "hUIfywXhNPQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code**"
      ],
      "metadata": {
        "id": "yhCiVYvS05eL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing dependencies and importing libraries"
      ],
      "metadata": {
        "id": "5Yvhtm5w1GUa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XNHK0UOknyO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dd03d6-697b-4ff8-e95e-ba9a0bac6795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q google-generativeai faiss-cpu\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Gemini API key and initializing the Gemini model"
      ],
      "metadata": {
        "id": "Q52DRe2J17bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Gemini API key\n",
        "GEMINI_API_KEY = \"\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Initialize Gemini Model\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "wYHrnBB72Jlw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot template"
      ],
      "metadata": {
        "id": "iH-8zgaE2GuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEW_SHOT_EXAMPLES = \"\"\"\n",
        "Examples:\n",
        "\n",
        "Code:\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "Response:\n",
        "{\n",
        "  \"summary\": \"This function performs addition of two numbers.\",\n",
        "  \"functions\": [\n",
        "    {\n",
        "      \"name\": \"add\",\n",
        "      \"description\": \"Returns the sum of two input values a and b.\"\n",
        "    }\n",
        "  ],\n",
        "  \"missing_docstrings\": \"def add(a, b):\\\\n    '''Adds two numbers and returns the result.'''\",\n",
        "  \"potential_improvements\": \"Add type hints for better clarity.\"\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ocoeS4Wt2VH3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate structured explanation with few-shot prompting"
      ],
      "metadata": {
        "id": "FGlUkN6A2Y8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_explanation(code_snippet: str, output_format=\"json\"):\n",
        "    if output_format.lower() == \"json\":\n",
        "        prompt = f\"\"\"\n",
        "You are a code documentation assistant. Respond only in JSON with:\n",
        "- summary\n",
        "- functions (name and description)\n",
        "- missing docstrings\n",
        "- potential improvements\n",
        "\n",
        "{FEW_SHOT_EXAMPLES}\n",
        "\n",
        "Now analyze this code:\n",
        "\n",
        "Code:\n",
        "{code_snippet}\n",
        "\"\"\"\n",
        "    else:  # Story format\n",
        "        prompt = f\"\"\"\n",
        "You are a code documentation assistant. Analyze the following code and explain it as a story\n",
        "in a creative, engaging way. Make the explanation accessible while still being technically accurate.\n",
        "Include information about:\n",
        "- What the code does\n",
        "- The functions and their purpose\n",
        "- Any missing documentation\n",
        "- Potential improvements\n",
        "\n",
        "Code:\n",
        "{code_snippet}\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        return extract_json_from_response(response.text)\n",
        "    else:\n",
        "        return {\"story\": response.text}"
      ],
      "metadata": {
        "id": "8odfBkqr2nSt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON extraction from response function"
      ],
      "metadata": {
        "id": "Si8WjfzMwC2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_json_from_response(text):\n",
        "    try:\n",
        "        # First try direct parsing\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # If that fails, try to extract JSON from markdown code blocks\n",
        "        json_pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n",
        "        match = re.search(json_pattern, text)\n",
        "        if match:\n",
        "            try:\n",
        "                return json.loads(match.group(1))\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        # If still no valid JSON, return error with raw output\n",
        "        return {\"error\": \"Model output not valid JSON\", \"raw_output\": text}"
      ],
      "metadata": {
        "id": "4ReHuTRewRtw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding generation"
      ],
      "metadata": {
        "id": "syk7AUgowYSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_code_embedding(code_snippet: str):\n",
        "    response = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=code_snippet,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )\n",
        "    return response['embedding']"
      ],
      "metadata": {
        "id": "zOZ_MuELwbdL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embed storing and implementing FAISS index"
      ],
      "metadata": {
        "id": "Z3EPD618LDxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 768  # 768 is the size of Gemini embeddings\n",
        "embedding_index = faiss.IndexFlatL2(embedding_dimension)\n",
        "code_snippets = []\n",
        "\n",
        "def store_code_snippet(code_snippet: str):\n",
        "    embedding = np.array([get_code_embedding(code_snippet)]).astype(\"float32\")\n",
        "    embedding_index.add(embedding)\n",
        "    code_snippets.append(code_snippet)\n",
        "\n",
        "def search_similar_code(query_snippet: str, top_k=1):\n",
        "    query_embedding = np.array([get_code_embedding(query_snippet)]).astype(\"float32\")\n",
        "    D, I = embedding_index.search(query_embedding, top_k)\n",
        "    return [code_snippets[i] for i in I[0]]"
      ],
      "metadata": {
        "id": "XvNaXWKqLIqM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG-style loop"
      ],
      "metadata": {
        "id": "cb8fxVHQLPh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_enhanced_explanation(query_code: str, output_format=\"json\"):\n",
        "    similar_snippets = search_similar_code(query_code)\n",
        "    context = \"\\n\\n\".join(similar_snippets)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        combined_prompt = f\"\"\"\n",
        "You are a code explanation assistant. Use the context below to help generate better explanation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "New Code:\n",
        "{query_code}\n",
        "\n",
        "Return your response in this structured JSON format:\n",
        "{{\n",
        "  \"summary\": \"...\",\n",
        "  \"functions\": [...],\n",
        "  \"missing_docstrings\": \"...\",\n",
        "  \"potential_improvements\": \"...\"\n",
        "}}\n",
        "\"\"\"\n",
        "    else:  # Story format\n",
        "        combined_prompt = f\"\"\"\n",
        "You are a code explanation assistant. Use the context below to help generate better explanation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "New Code:\n",
        "{query_code}\n",
        "\n",
        "Explain this code as an engaging story that a junior developer would find both entertaining and educational.\n",
        "Include information about what the code does, its functions, any missing documentation, and potential improvements.\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(combined_prompt)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        return extract_json_from_response(response.text)\n",
        "    else:\n",
        "        return {\"story\": response.text}"
      ],
      "metadata": {
        "id": "930OAkd1LTGx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation quality evaluation"
      ],
      "metadata": {
        "id": "wftYuBP_LbbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_explanation_quality(explanation: dict):\n",
        "    if \"error\" in explanation:\n",
        "        return f\"Error in explanation: {explanation['error']}\"\n",
        "    elif \"story\" in explanation:\n",
        "        word_count = len(explanation[\"story\"].split())\n",
        "        if word_count > 100:\n",
        "            return f\"Good story explanation with {word_count} words\"\n",
        "        return f\"Story explanation too short: {word_count} words\"\n",
        "    elif \"summary\" in explanation and len(explanation[\"summary\"].split()) > 3:\n",
        "        return \"Good summary\"\n",
        "    return \"Summary is too short or missing\"\n",
        "\n",
        "def print_explanation(explanation, output_format):\n",
        "    if output_format.lower() == \"json\":\n",
        "        print(json.dumps(explanation, indent=2))\n",
        "    else:  # Story format\n",
        "        if \"story\" in explanation:\n",
        "            print(\"\\n--- CODE STORY ---\\n\")\n",
        "            print(explanation[\"story\"])\n",
        "            print(\"\\n-----------------\\n\")\n",
        "        else:\n",
        "            print(\"Error generating story format\")\n",
        "            print(explanation)"
      ],
      "metadata": {
        "id": "nnbASXWoLeMP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Result**"
      ],
      "metadata": {
        "id": "cMPMD9wsLh5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Check if model is properly initialized\n",
        "    if model is None:\n",
        "        print(\"Error: Model is not initialized. Please configure your AI model first.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n=== CODE DOCUMENTATION ASSISTANT ===\")\n",
        "        print(\"1. Analyze code\")\n",
        "        print(\"2. Exit\")\n",
        "        choice = input(\"Enter your choice (1-2): \")\n",
        "\n",
        "        if choice == \"2\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Get code input\n",
        "            print(\"\\nEnter or paste your code (type 'DONE' on a new line when finished):\")\n",
        "            code_lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if line == \"DONE\":\n",
        "                    break\n",
        "                code_lines.append(line)\n",
        "\n",
        "            user_code = \"\\n\".join(code_lines)\n",
        "\n",
        "            if not user_code.strip():\n",
        "                print(\"No code provided. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            # Get format preference\n",
        "            format_choice = input(\"\\nChoose output format (json/story): \").lower()\n",
        "            output_format = \"json\" if format_choice == \"json\" else \"story\"\n",
        "\n",
        "            # Determine analysis method\n",
        "            analysis_method = input(\"\\nUse RAG enhancement? (y/n): \").lower()\n",
        "\n",
        "            print(\"\\nAnalyzing code...\")\n",
        "\n",
        "            # Store for future RAG comparisons\n",
        "            try:\n",
        "                store_code_snippet(user_code)\n",
        "                print(\"Code stored in vector database.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not store code in vector database. Error: {e}\")\n",
        "\n",
        "            # Generate explanation\n",
        "            try:\n",
        "                if analysis_method == \"y\":\n",
        "                    explanation = rag_enhanced_explanation(user_code, output_format)\n",
        "                    print(\"\\n=== RAG-ENHANCED EXPLANATION ===\")\n",
        "                else:\n",
        "                    explanation = generate_code_explanation(user_code, output_format)\n",
        "                    print(\"\\n=== BASIC EXPLANATION ===\")\n",
        "\n",
        "                print_explanation(explanation, output_format)\n",
        "                print(\"\\nEvaluation:\", evaluate_explanation_quality(explanation))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating explanation: {e}\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "btN022cqLjdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "54dddae7-c7c1-4f2b-bad4-568bfa7dd74f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CODE DOCUMENTATION ASSISTANT ===\n",
            "1. Analyze code\n",
            "2. Exit\n",
            "Enter your choice (1-2): 1\n",
            "\n",
            "Enter or paste your code (type 'DONE' on a new line when finished):\n",
            "<input type=\"text\" name=\"someName\" autocomplete=\"off\">  \n",
            "DONE\n",
            "\n",
            "Choose output format (json/story): json\n",
            "\n",
            "Use RAG enhancement? (y/n): y\n",
            "\n",
            "Analyzing code...\n",
            "Code stored in vector database.\n",
            "\n",
            "=== RAG-ENHANCED EXPLANATION ===\n",
            "{\n",
            "  \"summary\": \"The code snippet is an HTML input element of type 'text' with the name attribute set to 'someName' and the autocomplete attribute set to 'off'. This input field is likely intended for user input where the browser's autocomplete feature is disabled.\",\n",
            "  \"functions\": [],\n",
            "  \"missing_docstrings\": \"N/A (This is HTML, not a function definition)\",\n",
            "  \"potential_improvements\": \"While functional, consider adding a placeholder attribute to provide a hint to the user about what kind of input is expected. Also, depending on the context, adding an id attribute could be useful for JavaScript manipulation or CSS styling.  Consider adding a label element for accessibility.\"\n",
            "}\n",
            "\n",
            "Evaluation: Good summary\n",
            "\n",
            "=== CODE DOCUMENTATION ASSISTANT ===\n",
            "1. Analyze code\n",
            "2. Exit\n",
            "Enter your choice (1-2): 2\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}
