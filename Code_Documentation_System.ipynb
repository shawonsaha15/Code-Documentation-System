{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP50not+3woJ39MDlsv/wJL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Documentation System**"
      ],
      "metadata": {
        "id": "fbWuYvUAn2pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**\n",
        "\n",
        "This AI-powered Code Documentation System automates the generation of readable explanations and structured documentation for code snippets. Using 'gemini-2.0-flash' model's API, it provides summaries, identifies functions, suggests missing docstrings, and recommends improvements. Enhanced with embeddings and a RAG-style retrieval system, it delivers context-aware insights and supports both JSON and Markdown outputs. The tool simplifies code understanding, aiding developers and learners in writing and maintaining better software."
      ],
      "metadata": {
        "id": "tOAjRraDucsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "The Code Documentation Assistant is an interactive AI-powered tool designed to help developers generate high-quality explanations, summaries, and improvement suggestions for code snippets. Leveraging large language models with few-shot prompting, structured JSON outputs, and retrieval-augmented generation (RAG), this assistant supports multiple explanation formatsâ€”ranging from formal summaries to engaging, story-like descriptions.\n",
        "\n",
        "It integrates advanced features like code embeddings, vector search using FAISS, and long context window support through the Gemini API, allowing it to retrieve similar code examples to enrich understanding. The system also provides basic evaluation of explanation quality, making it an excellent tool for learning, onboarding, and improving code maintainability.\n",
        "\n",
        "Whether you're a junior developer trying to understand unfamiliar code or a senior engineer documenting a large codebase, this assistant streamlines the process with intelligent, context-aware outputs."
      ],
      "metadata": {
        "id": "tmQiJtzrud-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code**"
      ],
      "metadata": {
        "id": "yhCiVYvS05eL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing dependencies and importing libraries"
      ],
      "metadata": {
        "id": "5Yvhtm5w1GUa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNHK0UOknyO7"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q google-generativeai faiss-cpu\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Gemini API key and initializing the Gemini model"
      ],
      "metadata": {
        "id": "Q52DRe2J17bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Gemini API key\n",
        "GEMINI_API_KEY = \"AIzaSyBw4CpIbBOpmq8n3CNkLxaDzCIKutz4TWw\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Initialize Gemini Model\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "wYHrnBB72Jlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot template"
      ],
      "metadata": {
        "id": "iH-8zgaE2GuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEW_SHOT_EXAMPLES = \"\"\"\n",
        "Examples:\n",
        "\n",
        "Code:\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "Response:\n",
        "{\n",
        "  \"summary\": \"This function performs addition of two numbers.\",\n",
        "  \"functions\": [\n",
        "    {\n",
        "      \"name\": \"add\",\n",
        "      \"description\": \"Returns the sum of two input values a and b.\"\n",
        "    }\n",
        "  ],\n",
        "  \"missing_docstrings\": \"def add(a, b):\\\\n    '''Adds two numbers and returns the result.'''\",\n",
        "  \"potential_improvements\": \"Add type hints for better clarity.\"\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ocoeS4Wt2VH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate structured explanation with few-shot prompting"
      ],
      "metadata": {
        "id": "FGlUkN6A2Y8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_explanation(code_snippet: str, output_format=\"json\"):\n",
        "    if output_format.lower() == \"json\":\n",
        "        prompt = f\"\"\"\n",
        "You are a code documentation assistant. Respond only in JSON with:\n",
        "- summary\n",
        "- functions (name and description)\n",
        "- missing docstrings\n",
        "- potential improvements\n",
        "\n",
        "{FEW_SHOT_EXAMPLES}\n",
        "\n",
        "Now analyze this code:\n",
        "\n",
        "Code:\n",
        "{code_snippet}\n",
        "\"\"\"\n",
        "    else:  # Story format\n",
        "        prompt = f\"\"\"\n",
        "You are a code documentation assistant. Analyze the following code and explain it as a story\n",
        "in a creative, engaging way. Make the explanation accessible while still being technically accurate.\n",
        "Include information about:\n",
        "- What the code does\n",
        "- The functions and their purpose\n",
        "- Any missing documentation\n",
        "- Potential improvements\n",
        "\n",
        "Code:\n",
        "{code_snippet}\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        return extract_json_from_response(response.text)\n",
        "    else:\n",
        "        return {\"story\": response.text}"
      ],
      "metadata": {
        "id": "8odfBkqr2nSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON extraction from response function"
      ],
      "metadata": {
        "id": "Si8WjfzMwC2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_json_from_response(text):\n",
        "    try:\n",
        "        # First try direct parsing\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # If that fails, try to extract JSON from markdown code blocks\n",
        "        json_pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n",
        "        match = re.search(json_pattern, text)\n",
        "        if match:\n",
        "            try:\n",
        "                return json.loads(match.group(1))\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        # If still no valid JSON, return error with raw output\n",
        "        return {\"error\": \"Model output not valid JSON\", \"raw_output\": text}"
      ],
      "metadata": {
        "id": "4ReHuTRewRtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding generation"
      ],
      "metadata": {
        "id": "syk7AUgowYSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_code_embedding(code_snippet: str):\n",
        "    response = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=code_snippet,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )\n",
        "    return response['embedding']"
      ],
      "metadata": {
        "id": "zOZ_MuELwbdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embed storing and implementing FAISS index"
      ],
      "metadata": {
        "id": "Z3EPD618LDxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 768  # 768 is the size of Gemini embeddings\n",
        "embedding_index = faiss.IndexFlatL2(embedding_dimension)\n",
        "code_snippets = []\n",
        "\n",
        "def store_code_snippet(code_snippet: str):\n",
        "    embedding = np.array([get_code_embedding(code_snippet)]).astype(\"float32\")\n",
        "    embedding_index.add(embedding)\n",
        "    code_snippets.append(code_snippet)\n",
        "\n",
        "def search_similar_code(query_snippet: str, top_k=1):\n",
        "    query_embedding = np.array([get_code_embedding(query_snippet)]).astype(\"float32\")\n",
        "    D, I = embedding_index.search(query_embedding, top_k)\n",
        "    return [code_snippets[i] for i in I[0]]"
      ],
      "metadata": {
        "id": "XvNaXWKqLIqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG-style loop"
      ],
      "metadata": {
        "id": "cb8fxVHQLPh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_enhanced_explanation(query_code: str, output_format=\"json\"):\n",
        "    similar_snippets = search_similar_code(query_code)\n",
        "    context = \"\\n\\n\".join(similar_snippets)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        combined_prompt = f\"\"\"\n",
        "You are a code explanation assistant. Use the context below to help generate better explanation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "New Code:\n",
        "{query_code}\n",
        "\n",
        "Return your response in this structured JSON format:\n",
        "{{\n",
        "  \"summary\": \"...\",\n",
        "  \"functions\": [...],\n",
        "  \"missing_docstrings\": \"...\",\n",
        "  \"potential_improvements\": \"...\"\n",
        "}}\n",
        "\"\"\"\n",
        "    else:  # Story format\n",
        "        combined_prompt = f\"\"\"\n",
        "You are a code explanation assistant. Use the context below to help generate better explanation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "New Code:\n",
        "{query_code}\n",
        "\n",
        "Explain this code as an engaging story that a junior developer would find both entertaining and educational.\n",
        "Include information about what the code does, its functions, any missing documentation, and potential improvements.\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(combined_prompt)\n",
        "\n",
        "    if output_format.lower() == \"json\":\n",
        "        return extract_json_from_response(response.text)\n",
        "    else:\n",
        "        return {\"story\": response.text}"
      ],
      "metadata": {
        "id": "930OAkd1LTGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation quality evaluation"
      ],
      "metadata": {
        "id": "wftYuBP_LbbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_explanation_quality(explanation: dict):\n",
        "    if \"error\" in explanation:\n",
        "        return f\"Error in explanation: {explanation['error']}\"\n",
        "    elif \"story\" in explanation:\n",
        "        word_count = len(explanation[\"story\"].split())\n",
        "        if word_count > 100:\n",
        "            return f\"Good story explanation with {word_count} words\"\n",
        "        return f\"Story explanation too short: {word_count} words\"\n",
        "    elif \"summary\" in explanation and len(explanation[\"summary\"].split()) > 3:\n",
        "        return \"Good summary\"\n",
        "    return \"Summary is too short or missing\"\n",
        "\n",
        "def print_explanation(explanation, output_format):\n",
        "    if output_format.lower() == \"json\":\n",
        "        print(json.dumps(explanation, indent=2))\n",
        "    else:  # Story format\n",
        "        if \"story\" in explanation:\n",
        "            print(\"\\n--- CODE STORY ---\\n\")\n",
        "            print(explanation[\"story\"])\n",
        "            print(\"\\n-----------------\\n\")\n",
        "        else:\n",
        "            print(\"Error generating story format\")\n",
        "            print(explanation)"
      ],
      "metadata": {
        "id": "nnbASXWoLeMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Function"
      ],
      "metadata": {
        "id": "cMPMD9wsLh5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Check if model is properly initialized\n",
        "    if model is None:\n",
        "        print(\"Error: Model is not initialized. Please configure your AI model first.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n=== CODE DOCUMENTATION ASSISTANT ===\")\n",
        "        print(\"1. Analyze code\")\n",
        "        print(\"2. Exit\")\n",
        "        choice = input(\"Enter your choice (1-2): \")\n",
        "\n",
        "        if choice == \"2\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Get code input\n",
        "            print(\"\\nEnter or paste your code (type 'DONE' on a new line when finished):\")\n",
        "            code_lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if line == \"DONE\":\n",
        "                    break\n",
        "                code_lines.append(line)\n",
        "\n",
        "            user_code = \"\\n\".join(code_lines)\n",
        "\n",
        "            if not user_code.strip():\n",
        "                print(\"No code provided. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            # Get format preference\n",
        "            format_choice = input(\"\\nChoose output format (json/story): \").lower()\n",
        "            output_format = \"json\" if format_choice == \"json\" else \"story\"\n",
        "\n",
        "            # Determine analysis method\n",
        "            analysis_method = input(\"\\nUse RAG enhancement? (y/n): \").lower()\n",
        "\n",
        "            print(\"\\nAnalyzing code...\")\n",
        "\n",
        "            # Store for future RAG comparisons\n",
        "            try:\n",
        "                store_code_snippet(user_code)\n",
        "                print(\"Code stored in vector database.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not store code in vector database. Error: {e}\")\n",
        "\n",
        "            # Generate explanation\n",
        "            try:\n",
        "                if analysis_method == \"y\":\n",
        "                    explanation = rag_enhanced_explanation(user_code, output_format)\n",
        "                    print(\"\\n=== RAG-ENHANCED EXPLANATION ===\")\n",
        "                else:\n",
        "                    explanation = generate_code_explanation(user_code, output_format)\n",
        "                    print(\"\\n=== BASIC EXPLANATION ===\")\n",
        "\n",
        "                print_explanation(explanation, output_format)\n",
        "                print(\"\\nEvaluation:\", evaluate_explanation_quality(explanation))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating explanation: {e}\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "btN022cqLjdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}